import streamlit as st
import os
from dotenv import load_dotenv
from openai import OpenAI
from characters import CHARACTERS

load_dotenv()
token = os.environ.get("token")
# --- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ---
st.set_page_config(page_title="–¢–µ–ª–µ—Ñ–æ–Ω–Ω–∞—è –±—É–¥–∫–∞ üìû", page_icon="üìû")

# –ó–∞–º–µ–Ω–∏ –∫–ª—é—á –Ω–∞ —Å–≤–æ–π –∞–∫—Ç—É–∞–ª—å–Ω—ã–π
OPENAI_API_KEY = token

if "client" not in st.session_state:
    st.session_state.client = OpenAI(api_key=OPENAI_API_KEY)
if "messages" not in st.session_state:
    st.session_state.messages = []

# --- –ò–ù–¢–ï–†–§–ï–ô–° –£–ü–†–ê–í–õ–ï–ù–ò–Ø ---
with st.sidebar:
    st.header("–ù–∞—Å—Ç—Ä–æ–π–∫–∏")
    char_id = st.selectbox(
        "–ö–æ–º—É –∑–≤–æ–Ω–∏–º?",
        options=list(CHARACTERS.keys()),
        format_func=lambda x: CHARACTERS[x]["name"]
    )
    selected_char = CHARACTERS[char_id]

    if st.button("–°–±—Ä–æ—Å–∏—Ç—å —Ä–∞–∑–≥–æ–≤–æ—Ä üóëÔ∏è"):
        st.session_state.messages = []
        st.rerun()

st.title(f"–†–∞–∑–≥–æ–≤–æ—Ä: {selected_char['name']}")


# --- –õ–û–ì–ò–ö–ê AI ---
def get_ai_response(user_text, character, is_voice=False):
    client = st.session_state.client

    history = [{"role": m["role"], "content": m["content"]} for m in st.session_state.messages[-10:]]
    messages = [{"role": "system", "content": character["prompt"]}] + history + [{"role": "user", "content": user_text}]

    # 1. –¢–µ–∫—Å—Ç
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=messages
    )
    ai_text = response.choices[0].message.content

    # 2. –ì–æ–ª–æ—Å (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
    ai_audio_data = None
    if is_voice:
        voice_res = client.audio.speech.create(
            model="tts-1",
            voice=character["voice"],
            input=ai_text
        )
        ai_audio_data = voice_res.content

    return ai_text, ai_audio_data


# --- –û–¢–û–ë–†–ê–ñ–ï–ù–ò–ï –ß–ê–¢–ê ---
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        if "audio" in message:
            st.audio(message["audio"], format="audio/mp3")

# --- –û–ë–†–ê–ë–û–¢–ö–ê –í–í–û–î–ê ---
user_input = st.chat_input("–ù–∞–ø–∏—à–∏—Ç–µ —Å–æ–æ–±—â–µ–Ω–∏–µ...")
audio_value = st.audio_input("–ò–ª–∏ —Å–∫–∞–∂–∏—Ç–µ —á—Ç–æ-–Ω–∏–±—É–¥—å üéôÔ∏è")

prompt = None
is_audio_message = False

if user_input:
    prompt = user_input
elif audio_value:
    with st.spinner("–°–ª—É—à–∞—é..."):
        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –æ—à–∏–±–∫—É UnicodeEncodeError (ASCII)
        audio_value.name = "audio.wav"

        transcription = st.session_state.client.audio.transcriptions.create(
            model="whisper-1",
            file=audio_value
        )
        prompt = transcription.text
        is_audio_message = True

if prompt:
    # –°–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞
    with st.chat_message("assistant"):
        with st.spinner(f"{selected_char['name']} –ø–µ—á–∞—Ç–∞–µ—Ç..."):
            ai_text, ai_audio = get_ai_response(prompt, selected_char, is_voice=is_audio_message)

            st.markdown(ai_text)
            if ai_audio:
                st.audio(ai_audio, format="audio/mp3")

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    msg_data = {"role": "assistant", "content": ai_text}
    if ai_audio:
        msg_data["audio"] = ai_audio
    st.session_state.messages.append(msg_data)